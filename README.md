# 115_Electric_Motor_Fault_Diagnosis_based_on_Thermal_Images
Electric_Motor_Fault_Diagnosis_based_on_Thermal_Images_with_Machine_Learning

## Dataset: https://www.kaggle.com/datasets/python16/electric-motor-thermal-image-fault-diagnosis/data


ğŸ“ŠHÅ‘tÃ©rkÃ©pekbÅ‘l gÃ©pi tanulÃ¡ssal: villanymotor-hibÃ¡k elÅ‘rejelzÃ©se.

Az ipari prediktÃ­v karbantartÃ¡s egyik â€œtitkos fegyvereâ€ a termogrÃ¡fia: a motorok kÃ¼lsÅ‘ hÅ‘eloszlÃ¡sa (hÅ‘tÃ©rkÃ©pe) sokszor hamarabb elÃ¡rulja a hibÃ¡t, mint bÃ¡rmelyik zaj vagy teljesÃ­tmÃ©nycsÃ¶kkenÃ©s. Most egy olyan Colab-notebookot raktam Ã¶ssze, amely villanymotorok termÃ¡lkÃ©peibÅ‘l tanul Ã©s hiba / nincs hiba osztÃ¡lyozÃ¡st vÃ©gez kevÃ©s tanÃ­tÃ³adat mellett is stabilan.

1ï¸âƒ£Mit csinÃ¡l a notebook?

ğŸ“AdatforrÃ¡s: IR/termÃ¡l kÃ©pek villanymotorokrÃ³l, train/ Ã©s validation/ mappastruktÃºrÃ¡ban (binary: fault vs no_fault)

ğŸ“ElÅ‘feldolgozÃ¡s & augmentÃ¡ciÃ³: egysÃ©gesÃ­tÃ©s (224Ã—224), ImageNet-kompatibilis normalizÃ¡lÃ¡s, majd cÃ©lzott augmentÃ¡ciÃ³ (forgatÃ¡s, eltolÃ¡s, zoom, nyÃ­rÃ¡s, tÃ¼krÃ¶zÃ©s) a kevÃ©s minta ellen

ğŸ“Modell: ResNet50 backbone (ImageNet sÃºlyok, include_top=False) + GlobalAveragePooling + Dropout(0.4) + L2-regularizÃ¡lt sigmoid kimenet (binary)

ğŸ“TanÃ­tÃ¡s kis adaton: fagyasztott backbone-nal bemelegÃ­tÃ©s (Adam, BCE + label smoothing 0.05, metrikÃ¡k: Accuracy, AUC)

ğŸ“FinomhangolÃ¡s: a felsÅ‘ ~50 ResNet-rÃ©teg â€œfeloldÃ¡saâ€ (BatchNorm kivÃ©tel), alacsony LR, korai megÃ¡llÃ­tÃ¡s (EarlyStopping), ReduceLROnPlateau

ğŸ“OsztÃ¡ly-sÃºlyozÃ¡s a kiegyensÃºlyozottabb tanulÃ¡sÃ©rt

ğŸ“Ã‰rtÃ©kelÃ©s: Precision-Recall gÃ¶rbÃ©bÅ‘l F1-optimÃ¡lis dÃ¶ntÃ©si kÃ¼szÃ¶b kivÃ¡lasztÃ¡sa (nem csak 0.5!), konfÃºziÃ³s mÃ¡trix Ã©s jelentÃ©s

ğŸ“Extra: adat-szivÃ¡rgÃ¡s ellenÅ‘rzÃ©s (azonos fÃ¡jlnevek, bitegyezÃ©s SHA256-tal) a train/val kÃ¶zt

2ï¸âƒ£Inference / Ã¼zemeltetÃ©s: 1-kÃ©pes predikciÃ³, a kimenet rÃ¡Ã­rva az eredeti hÅ‘tÃ©rkÃ©pre, mentÃ©ssel

3ï¸âƒ£HÅ‘tÃ©rkÃ©pek (termogrÃ¡fia) lÃ©trehozÃ¡sa Ã©s szerepÃ¼k:

ğŸ“ŒLÃ©trehozÃ¡s: IR kamerÃ¡val rÃ¶gzÃ­tett radiometrikus felvÃ©telek â†’ egysÃ©ges hÅ‘skÃ¡la/kolormap â†’ zajszÅ±rÃ©s, opcionÃ¡lis ROI (motorhÃ¡z) kivÃ¡gÃ¡s â†’ 3-csatornÃ¡s bemenet a CNN-nek

ğŸ“ŒMiÃ©rt hasznos? A lokÃ¡lis forrÃ³pontok Ã©s aszimmetriÃ¡k gyakran megelÅ‘zik a meghibÃ¡sodÃ¡st:

csapÃ¡gymelegedÃ©s â†’ csapÃ¡gy-/kenÃ©si problÃ©mÃ¡k,

tekercshelyi hotspot â†’ szigetelÃ©si/tekercselÃ©si gond,

egyenetlen hÅ‘eloszlÃ¡s â†’ hÅ±tÃ©s/projektÃ¡lÃ¡si anomÃ¡lia, terhelÃ©s-aszimmetria.

 ğŸ“Œezzel a tervezett leÃ¡llÃ¡s idÅ‘zÃ­thetÅ‘, csÃ¶kken a nem tervezett kiesÃ©s

4ï¸âƒ£StratÃ©giÃ¡k kevÃ©s trÃ©ningkÃ©phez

Transzfer tanulÃ¡s (ImageNet-en elÅ‘tanÃ­tott ResNet50) â†’ kevesebb adat mellett is jÃ³ generalizÃ¡ciÃ³.

ErÅ‘s, de realistÃ¡n beÃ¡llÃ­tott augmentÃ¡ciÃ³ â†’ â€œmestersÃ©gesâ€ variancia a valÃ³sÃ¡gon belÃ¼l.

RegularizÃ¡ciÃ³ (Dropout + L2) Ã©s label smoothing â†’ kevÃ©s mintÃ¡n is robusztusabb dÃ¶ntÃ©si hatÃ¡r.

OsztÃ¡lysÃºlyok + F1-alapÃº kÃ¼szÃ¶b â†’ az Ã¼zemi kockÃ¡zatokhoz illesztett hiba/Ã¡lhiba kompromisszum.

Korai megÃ¡llÃ¡s, LR-lÃ©ptetÃ©s â†’ tÃºltanulÃ¡s megelÅ‘zÃ©se, stabil konvergencia.

SzivÃ¡rgÃ¡s-kontroll â†’ a validÃ¡ciÃ³ valÃ³ban valÃ³s teljesÃ­tmÃ©nyt mÃ©r.

Mit ad ez a karbantartÃ¡snak?

Korai jelzÃ©s: a hÅ‘tÃ©rkÃ©p-mintÃ¡zatok vÃ¡ltozÃ¡sÃ¡t a modell hamar Ã©szreveszi.

SkÃ¡lÃ¡zhatÃ³sÃ¡g: a pipeline Colabban fut, kÃ¶nnyen kontÃ©nerizÃ¡lhatÃ³ Ã©s integrÃ¡lhatÃ³ edge/gyÃ¡ri kÃ¶rnyezetbe.
